#!/usr/bin/env python3
# main.py
"""
SejmBot Scraper - G≈Ç√≥wny entry-point

Narzƒôdzie do pobierania wypowiedzi z posiedze≈Ñ Sejmu RP
bez pobierania PDF-√≥w - tylko przez API JSON/HTML.
Z zaawansowanƒÖ obs≈ÇugƒÖ cache dla wydajno≈õci.
"""

import argparse
import logging
import sys
from pathlib import Path

from config import LOG_LEVEL, LOG_FORMAT, LOGS_DIR, DEFAULT_TERM
from scraper import SejmScraper


def setup_logging(verbose: bool = False, log_file: str = None):
    """
    Konfiguruje system logowania

    Args:
        verbose: czy wy≈õwietlaƒá szczeg√≥≈Çowe logi
        log_file: ≈õcie≈ºka do pliku z logami (opcjonalne)
    """
    level = logging.DEBUG if verbose else getattr(logging, LOG_LEVEL.upper())

    # Usu≈Ñ istniejƒÖce handlery ≈ºeby uniknƒÖƒá duplikat√≥w
    root_logger = logging.getLogger()
    root_logger.handlers.clear()

    # Konfiguracja podstawowa - handler konsoli
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_formatter = logging.Formatter(LOG_FORMAT)
    console_handler.setFormatter(console_formatter)

    # Lista handler√≥w
    handlers = [console_handler]

    # Dodaj handler pliku je≈õli podano
    if log_file:
        # Upewnij siƒô, ≈ºe katalog logs istnieje
        logs_path = Path(LOGS_DIR)
        logs_path.mkdir(exist_ok=True)

        log_file_path = logs_path / log_file

        try:
            file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
            file_handler.setLevel(level)
            file_formatter = logging.Formatter(LOG_FORMAT)
            file_handler.setFormatter(file_formatter)
            handlers.append(file_handler)

            print(f"Logi bƒôdƒÖ zapisywane do: {log_file_path.absolute()}")

        except Exception as e:
            print(f"Ostrze≈ºenie: Nie mo≈ºna utworzyƒá pliku log√≥w {log_file_path}: {e}")
            print("Kontynujƒô tylko z logowaniem do konsoli.")

    # Konfiguruj logger podstawowy z handlerami
    root_logger.setLevel(level)
    for handler in handlers:
        root_logger.addHandler(handler)


def print_banner():
    """Wy≈õwietla banner aplikacji"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    SejmBot Scraper                           ‚ïë
‚ïë                                                              ‚ïë
‚ïë            Pobieranie wypowiedzi z Sejmu RP                  ‚ïë
‚ïë                  (bez PDF-√≥w, tylko API)                     ‚ïë
‚ïë                      Wersja 1.0.0                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """
    print(banner)


def print_term_info(scraper, term):
    """Wy≈õwietla informacje o kadencji"""
    try:
        # Pobierz informacje o kadencji
        term_info = scraper.api.get_term_info(term)
        if term_info:
            print(f"üìÖ Kadencja {term}: {term_info.get('from', '')} - {term_info.get('to', 'obecna')}")

        # Pobierz podsumowanie posiedze≈Ñ
        summary = scraper.get_term_proceedings_summary(term)
        if summary:
            total = len(summary)
            future = sum(1 for p in summary if p.get('is_future', False))
            current = sum(1 for p in summary if p.get('current', False))

            print(f"üèõÔ∏è  Posiedzenia: {total} og√≥≈Çem")
            if future > 0:
                print(f"‚≠ê  Przysz≈Çe: {future}")
            if current > 0:
                print(f"üîÑ Bie≈ºƒÖce: {current}")

    except Exception as e:
        logging.warning(f"Nie mo≈ºna pobraƒá informacji o kadencji: {e}")


def print_cache_stats(scraper: SejmScraper):
    """Wy≈õwietla szczeg√≥≈Çowe statystyki cache"""
    stats = scraper.get_cache_stats()

    print("\n" + "=" * 60)
    print("üìä STATYSTYKI CACHE")
    print("=" * 60)

    # API Cache
    api_stats = stats['api_cache']
    print(f"üîå API Cache:")
    print(f"   ≈ÅƒÖczne wpisy: {api_stats['total_entries']}")
    print(f"   Wygas≈Çe: {api_stats['expired']}")
    print(f"   Przestarza≈Çe (1h): {api_stats['stale_1h']}")
    print(f"   Przestarza≈Çe (24h): {api_stats['stale_24h']}")

    # File Cache
    file_stats = stats['file_cache']
    print(f"\nüìÑ File Cache:")
    print(f"   ≈ÅƒÖczne wpisy: {file_stats['total_entries']}")
    print(f"   Pliki istniejƒÖ: {file_stats['files_exist']}")
    print(f"   BrakujƒÖce pliki: {file_stats['files_missing']}")

    # Disk usage
    disk_stats = stats['disk_usage']
    print(f"\nüíæ U≈ºycie dysku:")
    print(f"   Rozmiar cache: {disk_stats['cache_dir_size_mb']:.2f} MB")

    # Recommendations
    print(f"\nüí° Rekomendacje:")
    if api_stats['expired'] > 0:
        print(f"   ‚Ä¢ Uruchom --cleanup-cache aby usunƒÖƒá {api_stats['expired']} wygas≈Çych wpis√≥w")

    if file_stats['files_missing'] > 0:
        print(
            f"   ‚Ä¢ {file_stats['files_missing']} plik√≥w z cache nie istnieje - cache zostanie automatycznie wyczyszczony")

    if disk_stats['cache_dir_size_mb'] > 100:
        print(f"   ‚Ä¢ Cache zajmuje du≈ºo miejsca - rozwa≈º --cleanup-cache")

    print("=" * 60)


def create_cli_parser():
    """Tworzy parser argument√≥w CLI z obs≈ÇugƒÖ cache"""
    parser = argparse.ArgumentParser(
        description="SejmBot Scraper - pobiera wypowiedzi z posiedze≈Ñ Sejmu RP (bez PDF-√≥w)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Przyk≈Çady u≈ºycia:
  %(prog)s                              # pobierz ca≈ÇƒÖ 10. kadencjƒô (tylko wypowiedzi)
  %(prog)s -t 9                         # pobierz 9. kadencjƒô 
  %(prog)s -t 10 -p 15                  # pobierz konkretne posiedzenie 15
  %(prog)s -t 10 --no-full-text         # bez pe≈Çnej tre≈õci wypowiedzi (szybciej)
  %(prog)s --list-terms                 # wy≈õwietl dostƒôpne kadencje
  %(prog)s -t 10 --summary              # podsumowanie posiedze≈Ñ bez pobierania
  %(prog)s -v --log-file scraper.log    # verbose z zapisem do pliku

ZarzƒÖdzanie cache:
  %(prog)s --cache-stats                # poka≈º statystyki cache
  %(prog)s --clear-cache                # wyczy≈õƒá cache
  %(prog)s --cleanup-cache              # wyczy≈õƒá stare wpisy z cache
  %(prog)s --force                      # wymu≈õ pobieranie (omi≈Ñ cache)
  %(prog)s --dry-run                    # tryb testowy - nie zapisuj danych

UWAGA: Program pobiera tylko wypowiedzi przez API (JSON/HTML).
       Nie pobiera PDF-√≥w stenogram√≥w.
        """
    )

    # G≈Ç√≥wne opcje
    parser.add_argument(
        '-t', '--term',
        type=int,
        default=DEFAULT_TERM,
        help=f'Numer kadencji (domy≈õlnie: {DEFAULT_TERM})'
    )

    parser.add_argument(
        '-p', '--proceeding',
        type=int,
        help='Numer konkretnego posiedzenia do pobrania'
    )

    # Opcje pobierania
    parser.add_argument(
        '--no-full-text',
        action='store_true',
        help='Nie pobieraj pe≈Çnej tre≈õci wypowiedzi (tylko podstawowe metadane)'
    )

    parser.add_argument(
        '--force',
        action='store_true',
        help='Wymu≈õ pobieranie - omi≈Ñ cache i pobierz wszystko ponownie'
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Tryb testowy - nie zapisuj danych, tylko poka≈º co by≈Çoby robione'
    )

    # Opcje cache
    parser.add_argument(
        '--clear-cache',
        action='store_true',
        help='Wyczy≈õƒá cache API i plik√≥w'
    )

    parser.add_argument(
        '--cache-stats',
        action='store_true',
        help='Wy≈õwietl statystyki cache'
    )

    parser.add_argument(
        '--cleanup-cache',
        action='store_true',
        help='Wyczy≈õƒá stare i wygas≈Çe wpisy z cache'
    )

    parser.add_argument(
        '--cache-type',
        choices=['api', 'files', 'all'],
        default='all',
        help='Typ cache do wyczyszczenia (u≈ºywane z --clear-cache)'
    )

    # Opcje informacyjne
    parser.add_argument(
        '--list-terms',
        action='store_true',
        help='Wy≈õwietl dostƒôpne kadencje i zako≈Ñcz'
    )

    parser.add_argument(
        '--summary',
        action='store_true',
        help='Wy≈õwietl podsumowanie posiedze≈Ñ bez pobierania danych'
    )

    # Opcje logowania
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Szczeg√≥≈Çowe logi (DEBUG level)'
    )

    parser.add_argument(
        '--log-file',
        type=str,
        help='Zapisuj logi do pliku (w katalogu logs/)'
    )

    return parser


def main():
    """G≈Ç√≥wna funkcja programu"""
    parser = create_cli_parser()
    args = parser.parse_args()

    # Konfiguruj logowanie przed jakƒÖkolwiek operacjƒÖ
    setup_logging(args.verbose, args.log_file)

    logger = logging.getLogger(__name__)

    # Sprawd≈∫ czy to tylko operacje na cache lub informacyjne
    cache_only_operations = [args.clear_cache, args.cache_stats, args.cleanup_cache]
    info_only_operations = [args.list_terms, args.summary]

    # Wy≈õwietl banner tylko dla g≈Ç√≥wnych operacji
    if not any(cache_only_operations + info_only_operations):
        print_banner()

    try:
        # Utw√≥rz scraper
        scraper = SejmScraper(force_refresh=args.force)

        if args.dry_run:
            print("üß™ TRYB TESTOWY - nie bƒôdƒÖ zapisywane ≈ºadne dane")

        # === OPERACJE TYLKO NA CACHE ===
        if args.clear_cache:
            print(f"üßπ Czyszczenie cache ({args.cache_type})...")
            scraper.clear_cache(args.cache_type)
            print("‚úÖ Cache wyczyszczony")
            return

        if args.cleanup_cache:
            print("üßπ Czyszczenie starych wpis√≥w z cache...")
            scraper.cleanup_cache()
            print("‚úÖ Stare wpisy usuniƒôte")
            return

        if args.cache_stats:
            print_cache_stats(scraper)
            return

        # === OPERACJE INFORMACYJNE ===
        # Lista dostƒôpnych kadencji
        if args.list_terms:
            print("üìã Dostƒôpne kadencje:")
            print("-" * 40)

            terms = scraper.get_available_terms()
            if terms:
                for term in reversed(terms):  # Najnowsze na g√≥rze
                    term_num = term.get('num', '?')
                    term_from = term.get('from', '')
                    term_to = term.get('to', 'obecna')
                    print(f"  Kadencja {term_num}: {term_from} - {term_to}")
            else:
                print("  Nie mo≈ºna pobraƒá listy kadencji")
            return

        # Podsumowanie posiedze≈Ñ
        if args.summary:
            print(f"üìä Podsumowanie kadencji {args.term}")
            print("-" * 50)

            print_term_info(scraper, args.term)

            summary = scraper.get_term_proceedings_summary(args.term)
            if summary:
                print(f"\nüìÑ Lista posiedze≈Ñ:")
                for proc in summary:
                    number = proc.get('number', '?')
                    title = proc.get('title', 'Bez tytu≈Çu')
                    dates = ', '.join(proc.get('dates', []))
                    status = ""

                    if proc.get('current'):
                        status = " [BIE≈ªƒÑCE]"
                    elif proc.get('is_future'):
                        status = " [PRZYSZ≈ÅE]"

                    # Skr√≥ƒá tytu≈Ç je≈õli za d≈Çugi
                    if len(title) > 60:
                        title = title[:57] + "..."

                    print(f"  {number:3d}. {title}")
                    print(f"       üìÖ {dates}{status}")
            else:
                print("Nie mo≈ºna pobraƒá listy posiedze≈Ñ")
            return

        # === G≈Å√ìWNE OPERACJE SCRAPOWANIA ===

        # Walidacja parametr√≥w
        if args.proceeding is not None and args.proceeding <= 0:
            print(f"B≈ÇƒÖd: Numer posiedzenia musi byƒá wiƒôkszy ni≈º 0 (podano: {args.proceeding})")
            sys.exit(1)

        if args.force:
            print("‚ö° TRYB WYMUSZONY - wszystkie dane zostanƒÖ pobrane ponownie")

        logging.info("Rozpoczynanie procesu pobierania wypowiedzi...")

        # Wy≈õwietl info o kadencji
        print_term_info(scraper, args.term)

        fetch_full_statements = not args.no_full_text

        if fetch_full_statements:
            print("üìÑ BƒôdƒÖ pobierane pe≈Çne tre≈õci wypowiedzi (mo≈ºe potrwaƒá d≈Çu≈ºej)")
        else:
            print("‚ö° Pobieranie tylko metadanych wypowiedzi (szybszy tryb)")

        # Konkretne posiedzenie
        if args.proceeding:
            print(f"\nüéØ Pobieranie posiedzenia {args.proceeding} z kadencji {args.term}")

            if not args.dry_run:
                success = scraper.scrape_specific_proceeding(
                    args.term,
                    args.proceeding,
                    fetch_full_statements
                )

                if success:
                    print(f"\n‚úÖ Pomy≈õlnie pobrano posiedzenie {args.proceeding}")
                else:
                    print(f"\n‚ùå B≈ÇƒÖd podczas pobierania posiedzenia {args.proceeding}")
                    sys.exit(1)
            else:
                print(f"üß™ Tryb testowy: pobrano by posiedzenie {args.proceeding}")

        # Ca≈Ça kadencja
        else:
            print(f"\nüèõÔ∏è  Pobieranie ca≈Çej kadencji {args.term}")
            print("‚è≥ To mo≈ºe potrwaƒá kilka minut...")

            if not args.dry_run:
                stats = scraper.scrape_term(args.term, fetch_full_statements, args.force)

                print(f"\nüìä PODSUMOWANIE POBIERANIA KADENCJI {args.term}")
                print("=" * 60)
                print(f"Przetworzone posiedzenia:     {stats['proceedings_processed']}")
                print(f"Pominiƒôte przysz≈Çe:           {stats['future_proceedings_skipped']}")
                print(f"Przetworzone wypowiedzi:      {stats['statements_processed']}")
                print(f"Wypowiedzi z pe≈ÇnƒÖ tre≈õciƒÖ:   {stats['statements_with_full_content']}")
                print(f"Zidentyfikowani m√≥wcy:        {stats['speakers_identified']}")
                print(f"Wzbogacenia danymi pos≈Ç√≥w:    {stats['mp_data_enrichments']}")
                print(f"B≈Çƒôdy:                        {stats['errors']}")
                print("=" * 60)

                if stats['errors'] > 0:
                    print(f"‚ö†Ô∏è  Proces zako≈Ñczony z {stats['errors']} b≈Çƒôdami. Sprawd≈∫ logi.")
                    sys.exit(1)
                else:
                    print("‚úÖ Proces zako≈Ñczony pomy≈õlnie!")
            else:
                print(f"üß™ Tryb testowy: pobrano by ca≈ÇƒÖ kadencjƒô {args.term}")

        # Wy≈õwietl informacjƒô o strukturze danych
        if not args.dry_run:
            print(f"\nüìÅ Dane zapisane w: {scraper.file_manager.base_dir}")
            print("üìã Struktura:")
            print("   ‚îî‚îÄ‚îÄ kadencja_XX/")
            print("       ‚îú‚îÄ‚îÄ posiedzenie_XXX_YYYY-MM-DD/")
            print("       ‚îÇ   ‚îú‚îÄ‚îÄ info_posiedzenia.json")
            print("       ‚îÇ   ‚îî‚îÄ‚îÄ transcripts/")
            print("       ‚îÇ       ‚îî‚îÄ‚îÄ transkrypty_YYYY-MM-DD.json")

            if not fetch_full_statements:
                print("\nüí° Wskaz√≥wka: Uruchom ponownie bez --no-full-text aby pobraƒá pe≈Çne tre≈õci")

        # Wy≈õwietl informacje o cache na koniec (tylko dla g≈Ç√≥wnych operacji)
        if not any(cache_only_operations + info_only_operations) and not args.dry_run:
            print("\nüíæ Cache info:")
            cache_stats = scraper.get_cache_stats()
            print(f"   API: {cache_stats['api_cache']['total_entries']} wpis√≥w")
            print(f"   Pliki: {cache_stats['file_cache']['total_entries']} wpis√≥w")
            print("   U≈ºyj --cache-stats aby zobaczyƒá szczeg√≥≈Çy")

    except KeyboardInterrupt:
        logging.info("Proces przerwany przez u≈ºytkownika (Ctrl+C)")
        print("\n\n‚èπÔ∏è  Proces przerwany przez u≈ºytkownika.")
        sys.exit(1)

    except Exception as e:
        logger.error(f"Nieoczekiwany b≈ÇƒÖd: {e}")
        logging.exception("Nieoczekiwany b≈ÇƒÖd programu")
        print(f"\n‚ùå Nieoczekiwany b≈ÇƒÖd: {e}")
        print("Sprawd≈∫ logi dla szczeg√≥≈Ç√≥w.")
        sys.exit(1)

    return 0


if __name__ == "__main__":
    exit(main())
